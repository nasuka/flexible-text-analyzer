import json
import os

import pandas as pd
import plotly.graph_objects as go
import streamlit as st

from schema.llm_providers import LLMModel, LLMProvider
from schema.topic import SentimentAnalysis, TopicAnalysisResult
from services.text_column_estimator import (
    estimate_text_column,
    get_text_column_recommendations,
)
from services.topic_extractor import LLMTopicExtractor


def create_topic_visualization(result: TopicAnalysisResult) -> go.Figure:
    """ãƒˆãƒ”ãƒƒã‚¯ã®å¯è¦–åŒ–"""
    if not result or not result.topics:
        return None

    # ãƒˆãƒ”ãƒƒã‚¯ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
    topic_names = [f"ãƒˆãƒ”ãƒƒã‚¯{t.id}: {t.name}" for t in result.topics]
    keyword_counts = [len(t.keywords) for t in result.topics]
    subtopic_counts = [len(t.subtopics) for t in result.topics]

    fig = go.Figure(
        data=[
            go.Bar(
                name="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°",
                x=topic_names,
                y=keyword_counts,
                yaxis="y",
                offsetgroup=1,
            ),
            go.Bar(
                name="ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯æ•°",
                x=topic_names,
                y=subtopic_counts,
                yaxis="y2",
                offsetgroup=2,
            ),
        ]
    )

    fig.update_layout(
        title="ãƒˆãƒ”ãƒƒã‚¯åˆ†æ",
        xaxis_title="ãƒˆãƒ”ãƒƒã‚¯",
        yaxis={"title": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°", "side": "left"},
        yaxis2={"title": "ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯æ•°", "side": "right", "overlaying": "y"},
        barmode="group",
        height=500,
    )

    return fig


def create_sentiment_chart(sentiment: SentimentAnalysis) -> go.Figure:
    """æ„Ÿæƒ…åˆ†æã®å¯è¦–åŒ–"""
    if not sentiment:
        return None

    labels = ["ãƒã‚¸ãƒ†ã‚£ãƒ–", "ä¸­ç«‹", "ãƒã‚¬ãƒ†ã‚£ãƒ–"]
    values = [
        sentiment.positive_ratio,
        sentiment.neutral_ratio,
        sentiment.negative_ratio,
    ]
    colors = ["#00CC96", "#FFA15A", "#EF553B"]

    fig = go.Figure(
        data=[
            go.Pie(
                labels=labels,
                values=values,
                marker_colors=colors,
                textinfo="label+percent",
                hole=0.3,
            )
        ]
    )

    fig.update_layout(title="æ„Ÿæƒ…åˆ†æ", height=400)

    return fig


def create_topic_network(result: TopicAnalysisResult) -> go.Figure:
    """ãƒˆãƒ”ãƒƒã‚¯ã¨ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"""
    if not result or not result.topics:
        return None

    try:
        import networkx as nx
    except ImportError:
        st.warning("NetworkXãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
        return None

    G = nx.Graph()

    # ãƒãƒ¼ãƒ‰ã®è¿½åŠ 
    for topic in result.topics:
        G.add_node(f"T{topic.id}", label=topic.name, type="topic", size=20)
        for subtopic in topic.subtopics:
            G.add_node(
                f"T{topic.id}S{subtopic.id}",
                label=subtopic.name,
                type="subtopic",
                size=10,
            )
            G.add_edge(f"T{topic.id}", f"T{topic.id}S{subtopic.id}")

    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®è¨ˆç®—
    pos = nx.spring_layout(G, k=2, iterations=50)

    # ã‚¨ãƒƒã‚¸ã®æç”»
    edge_x = []
    edge_y = []
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        edge_x.extend([x0, x1, None])
        edge_y.extend([y0, y1, None])

    edge_trace = go.Scatter(
        x=edge_x,
        y=edge_y,
        line={"width": 1, "color": "#888"},
        hoverinfo="none",
        mode="lines",
    )

    # ãƒãƒ¼ãƒ‰ã®æç”»
    node_x = []
    node_y = []
    node_text = []
    node_color = []
    node_size = []

    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        node_text.append(G.nodes[node]["label"])
        node_color.append("red" if G.nodes[node]["type"] == "topic" else "blue")
        node_size.append(G.nodes[node]["size"])

    node_trace = go.Scatter(
        x=node_x,
        y=node_y,
        mode="markers+text",
        hoverinfo="text",
        text=node_text,
        textposition="middle center",
        marker={
            "size": node_size,
            "color": node_color,
            "line": {"width": 2, "color": "white"},
        },
    )

    fig = go.Figure(
        data=[edge_trace, node_trace],
        layout={
            "title": "ãƒˆãƒ”ãƒƒã‚¯ãƒãƒƒãƒ—",
            "showlegend": False,
            "hovermode": "closest",
            "margin": {"b": 20, "l": 5, "r": 5, "t": 40},
            "annotations": [
                {
                    "text": "èµ¤: ãƒˆãƒ”ãƒƒã‚¯, é’: ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯",
                    "showarrow": False,
                    "xref": "paper",
                    "yref": "paper",
                    "x": 0.005,
                    "y": -0.002,
                }
            ],
            "xaxis": {"showgrid": False, "zeroline": False, "showticklabels": False},
            "yaxis": {"showgrid": False, "zeroline": False, "showticklabels": False},
        },
    )

    return fig


def main():
    st.title("LLMã«ã‚ˆã‚‹ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡º (Structured Output)")
    st.markdown("---")

    # LLM APIè¨­å®š
    st.header("LLMè¨­å®š")

    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠ
    provider_display_names = [provider.get_display_name() for provider in LLMProvider]
    selected_provider_display = st.selectbox(
        "LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼",
        provider_display_names,
        help="ä½¿ç”¨ã™ã‚‹LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„",
    )

    # é¸æŠã•ã‚ŒãŸãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’å–å¾—
    selected_provider = None
    for provider in LLMProvider:
        if provider.get_display_name() == selected_provider_display:
            selected_provider = provider
            break

    # APIã‚­ãƒ¼å…¥åŠ›
    api_key_label = f"{selected_provider.get_display_name()} API Key"
    api_key_help = f"{selected_provider.get_display_name()} APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"

    if selected_provider == LLMProvider.OPENAI:
        api_key = st.text_input(
            api_key_label,
            value=os.getenv("OPENAI_API_KEY", ""),
            type="password",
            help=api_key_help,
        )
    elif selected_provider == LLMProvider.OPENROUTER:
        api_key = st.text_input(
            api_key_label,
            value=os.getenv("OPENROUTER_API_KEY", ""),
            type="password",
            help=api_key_help,
        )
    else:
        api_key = st.text_input(
            api_key_label,
            type="password",
            help=api_key_help,
        )

    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    available_models = LLMModel.get_models_by_provider(selected_provider)
    model_display_names = [model.get_display_name() for model in available_models]

    selected_model_display = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«é¸æŠ",
        model_display_names,
        help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
    )

    # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
    selected_model = None
    for model in available_models:
        if model.get_display_name() == selected_model_display:
            selected_model = model
            break

    if not api_key:
        st.warning(f"{selected_provider.get_display_name()} APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.header("ãƒ‡ãƒ¼ã‚¿å…¥åŠ›")
    uploaded_file = st.file_uploader(
        "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=["csv"],
        help="ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
    )

    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)
            st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {len(df)}è¡Œ, {len(df.columns)}åˆ—")

            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            with st.expander("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                st.dataframe(df.head(), use_container_width=True)

            # ãƒ†ã‚­ã‚¹ãƒˆã‚«ãƒ©ãƒ æ¨å®š
            recommended_column, analysis = estimate_text_column(df)

            # ãƒ†ã‚­ã‚¹ãƒˆé¸æŠ
            st.header("åˆ†æè¨­å®š")

            # æ¨å¥¨ã‚«ãƒ©ãƒ è¡¨ç¤º
            if recommended_column:
                st.success(f"ğŸ’¡ æ¨å¥¨ãƒ†ã‚­ã‚¹ãƒˆã‚«ãƒ©ãƒ : **{recommended_column}**")

                with st.expander("ğŸ“Š ã‚«ãƒ©ãƒ åˆ†æè©³ç´°"):
                    recommendations = get_text_column_recommendations(df, top_n=3)
                    for i, rec in enumerate(recommendations):
                        col_name = rec["column"]
                        details = rec["details"]
                        st.write(
                            f"**{i + 1}ä½: {col_name}** (ã‚¹ã‚³ã‚¢: {rec['score']:.1f})"
                        )
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("æ—¥æœ¬èªç‡", f"{details['japanese_ratio']:.1%}")
                        with col2:
                            st.metric(
                                "ãƒ¦ãƒ‹ãƒ¼ã‚¯ç‡", f"{details['uniqueness_ratio']:.1%}"
                            )
                        with col3:
                            st.metric("å¹³å‡æ–‡å­—æ•°", f"{details['avg_length']:.0f}")
                        st.divider()

            # ã‚«ãƒ©ãƒ é¸æŠï¼ˆæ¨å¥¨ã‚«ãƒ©ãƒ ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ï¼‰
            default_index = 0
            if recommended_column and recommended_column in df.columns:
                default_index = df.columns.tolist().index(recommended_column)

            text_column = st.selectbox(
                "ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„",
                options=df.columns.tolist(),
                index=default_index,
                help="ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡ºã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€åˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„",
            )

            if text_column:
                # ãƒˆãƒ”ãƒƒã‚¯å®šç¾©æ–¹æ³•ã®é¸æŠ
                st.subheader("ãƒˆãƒ”ãƒƒã‚¯å®šç¾©æ–¹æ³•")
                extraction_method = st.radio(
                    "ãƒˆãƒ”ãƒƒã‚¯å®šç¾©æ–¹æ³•ã‚’é¸æŠ",
                    ["å®Œå…¨è‡ªå‹•", "ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ãƒˆãƒ”ãƒƒã‚¯"],
                    index=0,
                    help="å®Œå…¨è‡ªå‹•ï¼šLLMãŒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è‡ªå‹•ã§ãƒˆãƒ”ãƒƒã‚¯ã¨ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯ã‚’æ±ºå®š\nãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ï¼šæŒ‡å®šã—ãŸãƒˆãƒ”ãƒƒã‚¯ã‹ã‚‰è‡ªå‹•ã§ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯ã‚’ç”Ÿæˆ",
                )

                user_topics = None
                if extraction_method == "ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ãƒˆãƒ”ãƒƒã‚¯":
                    st.subheader("ãƒˆãƒ”ãƒƒã‚¯å®šç¾©")

                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ãƒˆãƒ”ãƒƒã‚¯ã‚’ç®¡ç†
                    if "user_defined_topics" not in st.session_state:
                        st.session_state.user_defined_topics = [""]

                    st.write(
                        "åˆ†æã—ãŸã„ãƒˆãƒ”ãƒƒã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯ã¯è‡ªå‹•ã§ç”Ÿæˆã•ã‚Œã¾ã™ã€‚"
                    )

                    # ãƒˆãƒ”ãƒƒã‚¯å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
                    topics_container = st.container()
                    with topics_container:
                        for i, topic in enumerate(st.session_state.user_defined_topics):
                            col1, col2 = st.columns([4, 1])
                            with col1:
                                new_topic = st.text_input(
                                    f"ãƒˆãƒ”ãƒƒã‚¯ {i + 1}",
                                    value=topic,
                                    key=f"user_topic_{i}",
                                    placeholder="ä¾‹: å•†å“ã®å“è³ªã«ã¤ã„ã¦",
                                )
                                st.session_state.user_defined_topics[i] = new_topic
                            with col2:
                                if st.button(
                                    "å‰Šé™¤",
                                    key=f"delete_topic_{i}",
                                    disabled=len(st.session_state.user_defined_topics)
                                    <= 1,
                                ):
                                    st.session_state.user_defined_topics.pop(i)
                                    st.rerun()

                    # ãƒˆãƒ”ãƒƒã‚¯è¿½åŠ ãƒœã‚¿ãƒ³
                    if st.button(
                        "ãƒˆãƒ”ãƒƒã‚¯è¿½åŠ ",
                        disabled=len(st.session_state.user_defined_topics) >= 8,
                    ):
                        st.session_state.user_defined_topics.append("")
                        st.rerun()

                    # ç©ºã§ãªã„ãƒˆãƒ”ãƒƒã‚¯ã®ã¿ã‚’å–å¾—
                    user_topics = [
                        topic.strip()
                        for topic in st.session_state.user_defined_topics
                        if topic.strip()
                    ]

                    if user_topics:
                        st.success(f"å®šç¾©ã•ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯: {len(user_topics)}å€‹")
                        for i, topic in enumerate(user_topics, 1):
                            st.write(f"{i}. {topic}")
                    else:
                        st.warning("å°‘ãªãã¨ã‚‚1ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
                st.subheader("åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
                col1, col2 = st.columns(2)
                with col1:
                    if extraction_method == "å®Œå…¨è‡ªå‹•":
                        auto_topics = st.checkbox("ãƒˆãƒ”ãƒƒã‚¯æ•°ã‚’è‡ªå‹•æ±ºå®š", value=True)
                        if not auto_topics:
                            n_topics = st.slider(
                                "ãƒˆãƒ”ãƒƒã‚¯æ•°", min_value=2, max_value=10, value=5
                            )
                        else:
                            n_topics = None
                    else:
                        n_topics = len(user_topics) if user_topics else None
                        st.info(
                            f"ãƒˆãƒ”ãƒƒã‚¯æ•°: {n_topics if n_topics else 0}å€‹ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ï¼‰"
                        )

                    auto_subtopics = st.checkbox("ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯æ•°ã‚’è‡ªå‹•æ±ºå®š", value=True)
                    if not auto_subtopics:
                        n_subtopics = st.slider(
                            "ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯æ•°", min_value=1, max_value=5, value=3
                        )
                    else:
                        n_subtopics = None

                with col2:
                    include_sentiment = st.checkbox("æ„Ÿæƒ…åˆ†æã‚’å«ã‚ã‚‹", value=True)
                    data_limit = st.slider(
                        "ãƒ‡ãƒ¼ã‚¿ä»¶æ•°",
                        min_value=10,
                        max_value=len(df),
                        value=len(df),
                    )

                # ãƒ‡ãƒ¼ã‚¿èª¬æ˜ã®å…¥åŠ›
                st.subheader("ãƒ‡ãƒ¼ã‚¿èª¬æ˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰")
                data_description = st.text_area(
                    "ãƒ‡ãƒ¼ã‚¿ã®èª¬æ˜ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                    placeholder="ä¾‹: YouTubeã®å•†å“ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆã€‚ä¸»ã«ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã«é–¢ã™ã‚‹é¡§å®¢ã®è©•ä¾¡ã‚„æ„è¦‹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚",
                    help="ãƒ‡ãƒ¼ã‚¿ã®å†…å®¹ã‚„èƒŒæ™¯ã‚’èª¬æ˜ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šé©åˆ‡ãªãƒˆãƒ”ãƒƒã‚¯æŠ½å‡ºãŒå¯èƒ½ã«ãªã‚Šã¾ã™",
                    height=80,
                )

                # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æŠ½å‡º
                filtered_texts = (
                    df[text_column].dropna().astype(str).tolist()[:data_limit]
                )
                st.info(f"åˆ†æãƒ‡ãƒ¼ã‚¿: {len(filtered_texts)}ãƒ†ã‚­ã‚¹ãƒˆ")

                # ãƒˆãƒ¼ã‚¯ãƒ³æ•°äºˆæ¸¬
                total_chars = sum(len(text) for text in filtered_texts)
                estimated_tokens = total_chars // 3
                st.warning(
                    f"äºˆæ¸¬ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {estimated_tokens:,} tokensï¼ˆAPIåˆ¶é™ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼‰"
                )

                # åˆ†æå®Ÿè¡Œ
                if st.button("LLMãƒˆãƒ”ãƒƒã‚¯æŠ½å‡ºå®Ÿè¡Œ", type="primary"):
                    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
                    if len(filtered_texts) < 5:
                        st.error("åˆ†æã«ã¯æœ€ä½5ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
                    elif (
                        extraction_method == "ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ãƒˆãƒ”ãƒƒã‚¯" and not user_topics
                    ):
                        st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ãƒˆãƒ”ãƒƒã‚¯ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                    else:
                        with st.spinner("LLMã«ã‚ˆã‚‹åˆ†æä¸­..."):
                            extractor = LLMTopicExtractor(api_key, selected_model.value)

                            # ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡º
                            st.write("ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡ºä¸­...")
                            progress_bar = st.progress(0)

                            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ãƒˆãƒ”ãƒƒã‚¯ã®å ´åˆã¯user_topicsã‚’æ¸¡ã™
                            if extraction_method == "ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ãƒˆãƒ”ãƒƒã‚¯":
                                topics_result = (
                                    extractor.extract_topics_with_predefined(
                                        filtered_texts,
                                        user_topics,
                                        n_subtopics,
                                        data_description,
                                    )
                                )
                            else:
                                topics_result = extractor.extract_topics(
                                    filtered_texts,
                                    n_topics,
                                    n_subtopics,
                                    data_description,
                                )
                            progress_bar.progress(50)

                            if topics_result:
                                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«çµæœã‚’ä¿å­˜
                                st.session_state["topics_result"] = topics_result
                                st.session_state["analysis_settings"] = {
                                    "provider": selected_provider.get_display_name(),
                                    "model": selected_model.get_display_name(),
                                    "extraction_method": extraction_method,
                                    "n_topics": n_topics if n_topics else "è‡ªå‹•æ±ºå®š",
                                    "n_subtopics": n_subtopics
                                    if n_subtopics
                                    else "è‡ªå‹•æ±ºå®š",
                                    "data_count": len(filtered_texts),
                                    "text_column": text_column,
                                    "data_description": data_description
                                    if data_description.strip()
                                    else "ãªã—",
                                }
                                st.success("ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡ºå®Œäº†")

                                # ãƒ¬ãƒãƒ¼ãƒˆ
                                st.header("åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")

                                # æ¦‚è¦
                                st.subheader("å…¨ä½“æ¦‚è¦")
                                st.write(topics_result.summary)

                                # ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§
                                st.subheader("ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§")

                                for topic in topics_result.topics:
                                    with st.expander(
                                        f"ãƒˆãƒ”ãƒƒã‚¯{topic.id}: {topic.name}"
                                    ):
                                        st.write(f"**èª¬æ˜:** {topic.description}")
                                        st.write(
                                            f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:** {', '.join(topic.keywords)}"
                                        )

                                        if topic.subtopics:
                                            st.write("**ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯:**")
                                            for subtopic in topic.subtopics:
                                                st.write(
                                                    f"  **{subtopic.name}**: {subtopic.description}"
                                                )
                                                st.write(
                                                    f"    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(subtopic.keywords)}"
                                                )

                                # å¯è¦–åŒ–
                                st.subheader("å¯è¦–åŒ–")

                                # ãƒˆãƒ”ãƒƒã‚¯ã‚°ãƒ©ãƒ•
                                fig_topics = create_topic_visualization(topics_result)
                                if fig_topics:
                                    st.plotly_chart(
                                        fig_topics, use_container_width=True
                                    )

                                # ãƒˆãƒ”ãƒƒã‚¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
                                fig_network = create_topic_network(topics_result)
                                if fig_network:
                                    st.plotly_chart(
                                        fig_network, use_container_width=True
                                    )

                                # æ„Ÿæƒ…åˆ†æ
                                if include_sentiment:
                                    st.write("æ„Ÿæƒ…åˆ†æä¸­...")
                                    sentiment_result = extractor.analyze_sentiment(
                                        filtered_texts
                                    )
                                    progress_bar.progress(100)

                                    if sentiment_result:
                                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«æ„Ÿæƒ…åˆ†æçµæœã‚‚ä¿å­˜
                                        st.session_state["sentiment_result"] = (
                                            sentiment_result
                                        )

                                        st.subheader("æ„Ÿæƒ…åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")

                                        col1, col2 = st.columns(2)
                                        with col1:
                                            st.metric(
                                                "å…¨ä½“æ„Ÿæƒ…",
                                                sentiment_result.overall_sentiment,
                                            )
                                            st.metric(
                                                "ãƒã‚¸ãƒ†ã‚£ãƒ–ç‡",
                                                f"{sentiment_result.positive_ratio:.1%}",
                                            )
                                            st.metric(
                                                "ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡",
                                                f"{sentiment_result.negative_ratio:.1%}",
                                            )

                                        with col2:
                                            fig_sentiment = create_sentiment_chart(
                                                sentiment_result
                                            )
                                            if fig_sentiment:
                                                st.plotly_chart(
                                                    fig_sentiment,
                                                    use_container_width=True,
                                                )

                                        # æ´å¯Ÿ
                                        st.write("**ä¸»è¦ãªæ´å¯Ÿ:**")
                                        for insight in sentiment_result.key_insights:
                                            st.write(f"â€¢ {insight}")

                                progress_bar.empty()

                            else:
                                st.error(
                                    "ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                                )

        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰çµæœã‚’è¡¨ç¤ºï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¾Œã‚‚ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œãªã„ï¼‰
    if "topics_result" in st.session_state:
        topics_result = st.session_state["topics_result"]
        analysis_settings = st.session_state.get("analysis_settings", {})
        sentiment_result = st.session_state.get("sentiment_result", None)

        # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
        st.subheader("ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›")

        # æ§‹é€ åŒ–JSONå‡ºåŠ›
        download_data = {
            "analysis_settings": analysis_settings,
            "topics": topics_result.dict(),
            "sentiment": sentiment_result.dict() if sentiment_result else None,
        }

        json_str = json.dumps(download_data, ensure_ascii=False, indent=2)

        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                label="åˆ†æãƒ¬ãƒãƒ¼ãƒˆ (JSON)",
                data=json_str,
                file_name="structured_topic_analysis.json",
                mime="application/json",
                key="download_json",
            )

        with col2:
            # CSVå½¢å¼ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§
            csv_data = []
            for topic in topics_result.topics:
                csv_data.append(
                    {
                        "ãƒˆãƒ”ãƒƒã‚¯ID": topic.id,
                        "ãƒˆãƒ”ãƒƒã‚¯å": topic.name,
                        "èª¬æ˜": topic.description,
                        "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ", ".join(topic.keywords),
                        "ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯æ•°": len(topic.subtopics),
                        "ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§": "; ".join(
                            [subtopic.name for subtopic in topic.subtopics]
                        ),
                    }
                )

            csv_df = pd.DataFrame(csv_data)
            csv_str = csv_df.to_csv(index=False, encoding="utf-8-sig")

            st.download_button(
                label="ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§ (CSV)",
                data=csv_str,
                file_name="topic_summary.csv",
                mime="text/csv",
                key="download_csv",
            )

    else:
        # ä½¿ç”¨æ–¹æ³•ã®èª¬æ˜
        with st.expander("ä½¿ç”¨æ–¹æ³•ãƒ»ç‰¹å¾´"):
            st.markdown("""
            ### ä½¿ç”¨æ–¹æ³•
            1. **OpenAI API Key**ã‚’[å–å¾—](https://platform.openai.com/api-keys)ã—ã¦å…¥åŠ›
            2. **Structured Outputå¯¾å¿œãƒ¢ãƒ‡ãƒ«**ã‚’é¸æŠ
            3. **CSVãƒ•ã‚¡ã‚¤ãƒ«**ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            4. **ãƒ†ã‚­ã‚¹ãƒˆåˆ—**ã‚’é¸æŠ
            5. **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**ã‚’è¨­å®š
            6. **LLMãƒˆãƒ”ãƒƒã‚¯æŠ½å‡ºå®Ÿè¡Œ**ã‚’ã‚¯ãƒªãƒƒã‚¯

            ### Structured Outputã®ç‰¹å¾´
            - **é«˜ç²¾åº¦**: æ§‹é€ åŒ–ã•ã‚ŒãŸå‡ºåŠ›ã§åˆ†æ
            - **è©³ç´°ãªåˆ†æ**: ãƒˆãƒ”ãƒƒã‚¯ã¨ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯ã®éšå±¤æ§‹é€ 
            - **åŠ¹ç‡çš„**: è‡ªå‹•çš„ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†
            - **é«˜é€Ÿå‡¦ç†**: ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹åŠ¹ç‡åŒ–

            ### ã‚µãƒ³ãƒ—ãƒ«CSVå½¢å¼
            ```csv
            id,comment,author,date
            1,ç´ æ™´ã‚‰ã—ã„å•†å“ã§ã—ãŸ,ãƒ¦ãƒ¼ã‚¶ãƒ¼1,2024-01-01
            2,æ”¹å–„ãŒå¿…è¦ãªç‚¹ãŒã‚ã‚Šã¾ã™,ãƒ¦ãƒ¼ã‚¶ãƒ¼2,2024-01-02
            3,æœŸå¾…ä»¥ä¸Šã®å“è³ªã§ã™,ãƒ¦ãƒ¼ã‚¶ãƒ¼3,2024-01-03
            ```

            ### æ³¨æ„äº‹é …
            - **APIåˆ¶é™**: å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹å ´åˆã¯æ³¨æ„
            - **å‡¦ç†æ™‚é–“**: ãƒ‡ãƒ¼ã‚¿é‡ã«å¿œã˜ã¦æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™
            - **ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™**: ãƒ¢ãƒ‡ãƒ«ã®åˆ¶é™ã«æ³¨æ„
            - **æ¨å¥¨ãƒ¢ãƒ‡ãƒ«**: gpt-4oã‚’æ¨å¥¨

            ### ä¸»ãªæ©Ÿèƒ½
            - **ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡º**: ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡º
            - **æ§‹é€ åŒ–å‡ºåŠ›**: éšå±¤çš„ãªåˆ†æçµæœã‚’æä¾›
            - **å¯è¦–åŒ–**: ã‚°ãƒ©ãƒ•ã«ã‚ˆã‚‹ç›´æ„Ÿçš„ãªç†è§£
            - **æ„Ÿæƒ…åˆ†æ**: ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…å‚¾å‘ã‚’åˆ†æ
            """)


if __name__ == "__main__":
    main()
