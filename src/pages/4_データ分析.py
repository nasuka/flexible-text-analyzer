import json
import os

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

from schema.data_analysis import AnalysisResult, DataExtractionMethod
from schema.llm_providers import LLMModel, LLMProvider
from services.data_analyzer import LLMDataAnalyzer
from services.text_column_estimator import (
    estimate_text_column,
    get_text_column_recommendations,
)


def create_extraction_chart(extraction_result) -> go.Figure:
    """ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºçµæœã®å¯è¦–åŒ–"""
    labels = ["æŠ½å‡ºãƒ‡ãƒ¼ã‚¿", "ãã®ä»–"]
    values = [extraction_result.extracted_count, extraction_result.total_count - extraction_result.extracted_count]
    colors = ["#00CC96", "#FFA15A"]

    fig = go.Figure(
        data=[
            go.Pie(
                labels=labels,
                values=values,
                marker_colors=colors,
                textinfo="label+percent+value",
                hole=0.3,
            )
        ]
    )

    fig.update_layout(
        title=f"ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºçµæœ ({extraction_result.method.value})",
        height=400,
    )

    return fig


def create_confidence_gauge(confidence_score: float) -> go.Figure:
    """ä¿¡é ¼åº¦ã‚²ãƒ¼ã‚¸ã®ä½œæˆ"""
    fig = go.Figure(
        go.Indicator(
            mode="gauge+number+delta",
            value=confidence_score * 100,
            domain={"x": [0, 1], "y": [0, 1]},
            title={"text": "åˆ†æä¿¡é ¼åº¦"},
            delta={"reference": 80},
            gauge={
                "axis": {"range": [None, 100]},
                "bar": {"color": "darkblue"},
                "steps": [
                    {"range": [0, 50], "color": "lightgray"},
                    {"range": [50, 80], "color": "yellow"},
                    {"range": [80, 100], "color": "green"},
                ],
                "threshold": {
                    "line": {"color": "red", "width": 4},
                    "thickness": 0.75,
                    "value": 90,
                },
            },
        )
    )

    fig.update_layout(height=400)
    return fig


def main():
    st.title("ğŸ¤– ãƒ†ã‚­ã‚¹ãƒˆæŒ‡ç¤ºã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿åˆ†æ")
    st.markdown("---")

    # LLM APIè¨­å®š
    st.header("ğŸ”‘ LLMè¨­å®š")

    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠ
    provider_display_names = [provider.get_display_name() for provider in LLMProvider]
    selected_provider_display = st.selectbox(
        "LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼",
        provider_display_names,
        help="ä½¿ç”¨ã™ã‚‹LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„",
    )

    # é¸æŠã•ã‚ŒãŸãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’å–å¾—
    selected_provider = None
    for provider in LLMProvider:
        if provider.get_display_name() == selected_provider_display:
            selected_provider = provider
            break

    # APIã‚­ãƒ¼å…¥åŠ›
    api_key_label = f"{selected_provider.get_display_name()} API Key"
    api_key_help = f"{selected_provider.get_display_name()} APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"

    if selected_provider == LLMProvider.OPENAI:
        api_key = st.text_input(
            api_key_label,
            value=os.getenv("OPENAI_API_KEY", ""),
            type="password",
            help=api_key_help,
        )
    elif selected_provider == LLMProvider.OPENROUTER:
        api_key = st.text_input(
            api_key_label,
            value=os.getenv("OPENROUTER_API_KEY", ""),
            type="password",
            help=api_key_help,
        )
    else:
        api_key = st.text_input(
            api_key_label,
            type="password",
            help=api_key_help,
        )

    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    available_models = LLMModel.get_models_by_provider(selected_provider)
    model_display_names = [model.get_display_name() for model in available_models]

    selected_model_display = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«é¸æŠ",
        model_display_names,
        help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
    )

    # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
    selected_model = None
    for model in available_models:
        if model.get_display_name() == selected_model_display:
            selected_model = model
            break

    if not api_key:
        st.warning(f"{selected_provider.get_display_name()} APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.header("ğŸ“ ãƒ‡ãƒ¼ã‚¿å…¥åŠ›")
    uploaded_file = st.file_uploader(
        "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=["csv"],
        help="åˆ†æã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
    )

    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)
            st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {len(df)}è¡Œ, {len(df.columns)}åˆ—")

            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            with st.expander("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                st.dataframe(df.head(), use_container_width=True)

            # ãƒ†ã‚­ã‚¹ãƒˆã‚«ãƒ©ãƒ æ¨å®š
            recommended_column, analysis = estimate_text_column(df)

            # ãƒ†ã‚­ã‚¹ãƒˆé¸æŠ
            st.header("âš™ï¸ åˆ†æè¨­å®š")

            # æ¨å¥¨ã‚«ãƒ©ãƒ è¡¨ç¤º
            if recommended_column:
                st.success(f"ğŸ’¡ æ¨å¥¨ãƒ†ã‚­ã‚¹ãƒˆã‚«ãƒ©ãƒ : **{recommended_column}**")

                with st.expander("ğŸ“ˆ ã‚«ãƒ©ãƒ åˆ†æè©³ç´°"):
                    recommendations = get_text_column_recommendations(df, top_n=3)
                    for i, rec in enumerate(recommendations):
                        col_name = rec["column"]
                        details = rec["details"]
                        st.write(f"**{i + 1}ä½: {col_name}** (ã‚¹ã‚³ã‚¢: {rec['score']:.1f})")
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("æ—¥æœ¬èªç‡", f"{details['japanese_ratio']:.1%}")
                        with col2:
                            st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯ç‡", f"{details['uniqueness_ratio']:.1%}")
                        with col3:
                            st.metric("å¹³å‡æ–‡å­—æ•°", f"{details['avg_length']:.0f}")
                        st.divider()

            # ã‚«ãƒ©ãƒ é¸æŠï¼ˆæ¨å¥¨ã‚«ãƒ©ãƒ ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ï¼‰
            default_index = 0
            if recommended_column and recommended_column in df.columns:
                default_index = df.columns.tolist().index(recommended_column)

            text_column = st.selectbox(
                "ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„",
                options=df.columns.tolist(),
                index=default_index,
                help="åˆ†æã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€åˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„",
            )

            # åˆ©ç”¨å¯èƒ½ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚«ãƒ©ãƒ ã®æ¤œå‡º
            metadata_columns = []
            topic_columns = [col for col in df.columns if "topic" in col.lower() or "ãƒˆãƒ”ãƒƒã‚¯" in col]
            sentiment_columns = [col for col in df.columns if "sentiment" in col.lower() or "æ„Ÿæƒ…" in col]
            classification_columns = [col for col in df.columns if "classification" in col.lower() or "åˆ†é¡" in col]

            if topic_columns:
                metadata_columns.extend(topic_columns)
            if sentiment_columns:
                metadata_columns.extend(sentiment_columns)
            if classification_columns:
                metadata_columns.extend(classification_columns)

            if metadata_columns:
                st.info(f"ğŸ·ï¸ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚«ãƒ©ãƒ ã‚’æ¤œå‡ºã—ã¾ã—ãŸ: {', '.join(metadata_columns)}")
                st.write("ã“ã‚Œã‚‰ã®ã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨ã—ã¦ã‚ˆã‚Šç²¾å¯†ãªãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãŒå¯èƒ½ã§ã™ã€‚")

            # åˆ†ææŒ‡ç¤ºã®å…¥åŠ›
            st.header("ğŸ’¬ åˆ†ææŒ‡ç¤º")
            
            # ã‚µãƒ³ãƒ—ãƒ«æŒ‡ç¤ºã®è¡¨ç¤º
            with st.expander("ğŸ’¡ ã‚µãƒ³ãƒ—ãƒ«æŒ‡ç¤º"):
                st.markdown("""
                **åŸºæœ¬çš„ãªåˆ†ææŒ‡ç¤ºã®ä¾‹:**
                - "ãƒã‚¸ãƒ†ã‚£ãƒ–ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’è¦ç´„ã—ã¦åˆ†æã—ã¦"
                - "å•†å“ã®å“è³ªã«ã¤ã„ã¦è¨€åŠã—ã¦ã„ã‚‹å†…å®¹ã‚’åˆ†æ"
                - "ãƒã‚¬ãƒ†ã‚£ãƒ–ãªæ„è¦‹ã®ä¸»è¦ãªå•é¡Œç‚¹ã‚’æŠ½å‡º"
                - "ä¾¡æ ¼ã«é–¢ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã®å‚¾å‘ã‚’åˆ†æ"
                - "æ”¹å–„ææ¡ˆã‚’å«ã‚€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åˆ†é¡"
                
                **é«˜åº¦ãªåˆ†ææŒ‡ç¤ºã®ä¾‹:**
                - "æº€è¶³åº¦ã®é«˜ã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰æˆåŠŸè¦å› ã‚’åˆ†æ"
                - "è‹¦æƒ…ã‚³ãƒ¡ãƒ³ãƒˆã‹ã‚‰æ”¹å–„ã™ã¹ãç‚¹ã‚’ç‰¹å®š"
                - "ç«¶åˆä»–ç¤¾ã¨ã®æ¯”è¼ƒè¨€åŠã‚’æŠ½å‡ºã—ã¦åˆ†æ"
                - "ãƒªãƒ”ãƒ¼ãƒˆè³¼å…¥ã«é–¢ã™ã‚‹è¨€åŠã‚’åˆ†æ"
                """)

            analysis_instruction = st.text_area(
                "åˆ†æã—ãŸã„å†…å®¹ã‚’è‡ªç„¶ãªè¨€è‘‰ã§å…¥åŠ›ã—ã¦ãã ã•ã„",
                placeholder="ä¾‹: ãƒã‚¸ãƒ†ã‚£ãƒ–ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’è¦ç´„ã—ã¦ã€ã©ã®ã‚ˆã†ãªç‚¹ãŒè©•ä¾¡ã•ã‚Œã¦ã„ã‚‹ã‹åˆ†æã—ã¦ãã ã•ã„",
                help="ã€Œâ—‹â—‹ã«ã¤ã„ã¦åˆ†æã—ã¦ã€ã€ŒÃ—Ã—ã‚’è¦ç´„ã—ã¦ã€ãªã©ã®è‡ªç„¶ãªæŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚AIãŒæŒ‡ç¤ºã‚’è§£é‡ˆã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºãƒ»åˆ†æã—ã¾ã™ã€‚",
                height=100,
            )

            if analysis_instruction.strip():
                # ãƒ‡ãƒ¼ã‚¿åˆ¶é™è¨­å®š
                col1, col2 = st.columns(2)
                with col1:
                    data_limit = st.slider(
                        "åˆ†æãƒ‡ãƒ¼ã‚¿ä»¶æ•°",
                        min_value=10,
                        max_value=min(1000, len(df)),
                        value=min(500, len(df)),
                        help="å‡¦ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§ä»¶æ•°ï¼ˆAPIåˆ¶é™ã¨ã‚³ã‚¹ãƒˆã‚’è€ƒæ…®ã—ã¦ãã ã•ã„ï¼‰",
                    )

                with col2:
                    # ãƒˆãƒ¼ã‚¯ãƒ³æ•°äºˆæ¸¬
                    sample_texts = df[text_column].dropna().head(data_limit)
                    total_chars = sum(len(str(text)) for text in sample_texts)
                    estimated_tokens = total_chars // 3
                    st.metric("äºˆæ¸¬ãƒˆãƒ¼ã‚¯ãƒ³æ•°", f"{estimated_tokens:,}")

                # åˆ†æå®Ÿè¡Œ
                if st.button("ğŸš€ åˆ†æå®Ÿè¡Œ", type="primary"):
                    if len(df) < 5:
                        st.error("åˆ†æã«ã¯æœ€ä½5ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
                    else:
                        with st.spinner("ğŸ¤– AIãŒæŒ‡ç¤ºã‚’è§£æã—ã€ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æä¸­..."):
                            # ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–
                            analyzer = LLMDataAnalyzer(api_key, selected_model.value)

                            # åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚’åˆ¶é™
                            analysis_df = df.head(data_limit)

                            # åˆ†æå®Ÿè¡Œ
                            progress_bar = st.progress(0)
                            st.write("ğŸ“‹ æŒ‡ç¤ºã‚’è§£æä¸­...")
                            progress_bar.progress(20)

                            analysis_result = analyzer.analyze_with_instruction(
                                analysis_df, analysis_instruction, text_column, df.columns.tolist()
                            )

                            progress_bar.progress(100)

                            if analysis_result:
                                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«çµæœã‚’ä¿å­˜
                                st.session_state["analysis_result"] = analysis_result
                                st.session_state["analysis_settings"] = {
                                    "provider": selected_provider.get_display_name(),
                                    "model": selected_model.get_display_name(),
                                    "instruction": analysis_instruction,
                                    "text_column": text_column,
                                    "data_count": len(analysis_df),
                                    "metadata_columns": metadata_columns,
                                }

                                st.success("âœ… åˆ†æå®Œäº†ï¼")

                                # çµæœè¡¨ç¤º
                                st.header("ğŸ“Š åˆ†æçµæœ")

                                # æ¦‚è¦
                                st.subheader("ğŸ“‹ åˆ†ææ¦‚è¦")
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric(
                                        "æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ä»¶æ•°",
                                        analysis_result.extraction_result.extracted_count,
                                    )
                                with col2:
                                    st.metric(
                                        "æŠ½å‡ºç‡",
                                        f"{analysis_result.extraction_result.extracted_count / analysis_result.extraction_result.total_count:.1%}",
                                    )
                                with col3:
                                    st.metric(
                                        "ä¿¡é ¼åº¦",
                                        f"{analysis_result.confidence_score:.1%}",
                                    )

                                # è§£æã•ã‚ŒãŸæŒ‡ç¤ºã®è¡¨ç¤º
                                with st.expander("ğŸ” AIè§£æçµæœ: æŒ‡ç¤ºã®æ§‹é€ åŒ–"):
                                    instruction = analysis_result.instruction
                                    st.write(f"**å…ƒã®æŒ‡ç¤º:** {instruction.original_instruction}")
                                    st.write(f"**æŠ½å‡ºæ–¹æ³•:** {instruction.extraction_method.value}")
                                    st.write(f"**æŠ½å‡ºæ¡ä»¶:** {instruction.extraction_condition}")
                                    st.write(f"**åˆ†æã‚¿ã‚¤ãƒ—:** {instruction.analysis_type.value}")
                                    if instruction.specific_requirements:
                                        st.write(f"**å…·ä½“çš„è¦ä»¶:** {', '.join(instruction.specific_requirements)}")

                                # ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºçµæœ
                                st.subheader("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºçµæœ")
                                col1, col2 = st.columns([2, 1])
                                with col1:
                                    st.write(analysis_result.extraction_result.summary)

                                with col2:
                                    fig_extraction = create_extraction_chart(analysis_result.extraction_result)
                                    st.plotly_chart(fig_extraction, use_container_width=True)

                                # åˆ†æçµæœ
                                st.subheader("ğŸ¯ åˆ†æçµæœ")
                                st.write(analysis_result.analysis_summary)

                                # ä¸»è¦ãªç™ºè¦‹
                                if analysis_result.key_findings:
                                    st.subheader("ğŸ” ä¸»è¦ãªç™ºè¦‹")
                                    for finding in analysis_result.key_findings:
                                        st.write(f"â€¢ {finding}")

                                # ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
                                if analysis_result.insights:
                                    st.subheader("ğŸ’¡ ã‚¤ãƒ³ã‚µã‚¤ãƒˆ")
                                    for insight in analysis_result.insights:
                                        st.write(f"â€¢ {insight}")

                                # æ¨å¥¨äº‹é …
                                if analysis_result.recommendations:
                                    st.subheader("ğŸ“ æ¨å¥¨äº‹é …")
                                    for recommendation in analysis_result.recommendations:
                                        st.write(f"â€¢ {recommendation}")

                                # ä¿¡é ¼åº¦ã‚²ãƒ¼ã‚¸
                                col1, col2 = st.columns([1, 1])
                                with col2:
                                    fig_confidence = create_confidence_gauge(analysis_result.confidence_score)
                                    st.plotly_chart(fig_confidence, use_container_width=True)

                                progress_bar.empty()

                            else:
                                st.error("âŒ åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ã‚„æŒ‡ç¤ºå†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„")

        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰çµæœã‚’è¡¨ç¤ºï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¾Œã‚‚ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œãªã„ï¼‰
    if "analysis_result" in st.session_state:
        analysis_result: AnalysisResult = st.session_state["analysis_result"]
        analysis_settings = st.session_state.get("analysis_settings", {})

        # çµæœå‡ºåŠ›
        st.subheader("ğŸ’¾ çµæœå‡ºåŠ›")

        # æ§‹é€ åŒ–JSONå‡ºåŠ›
        download_data = {
            "analysis_settings": analysis_settings,
            "instruction": analysis_result.instruction.dict(),
            "extraction_result": analysis_result.extraction_result.dict(),
            "analysis_summary": analysis_result.analysis_summary,
            "key_findings": analysis_result.key_findings,
            "insights": analysis_result.insights,
            "recommendations": analysis_result.recommendations,
            "confidence_score": analysis_result.confidence_score,
        }

        json_str = json.dumps(download_data, ensure_ascii=False, indent=2)

        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                label="ğŸ“„ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ (JSON)",
                data=json_str,
                file_name="data_analysis_result.json",
                mime="application/json",
                key="download_json",
            )

        with col2:
            # ç°¡æ˜“CSVå‡ºåŠ›
            csv_data = {
                "æŒ‡ç¤º": [analysis_result.instruction.original_instruction],
                "æŠ½å‡ºæ–¹æ³•": [analysis_result.instruction.extraction_method.value],
                "æŠ½å‡ºæ¡ä»¶": [analysis_result.instruction.extraction_condition],
                "åˆ†æã‚¿ã‚¤ãƒ—": [analysis_result.instruction.analysis_type.value],
                "æŠ½å‡ºä»¶æ•°": [analysis_result.extraction_result.extracted_count],
                "ç·ä»¶æ•°": [analysis_result.extraction_result.total_count],
                "ä¿¡é ¼åº¦": [f"{analysis_result.confidence_score:.1%}"],
                "ä¸»è¦ç™ºè¦‹": ["; ".join(analysis_result.key_findings)],
                "ã‚¤ãƒ³ã‚µã‚¤ãƒˆ": ["; ".join(analysis_result.insights)],
                "æ¨å¥¨äº‹é …": ["; ".join(analysis_result.recommendations)],
            }

            csv_df = pd.DataFrame(csv_data)
            csv_str = csv_df.to_csv(index=False, encoding="utf-8-sig")

            st.download_button(
                label="ğŸ“Š åˆ†æã‚µãƒãƒªãƒ¼ (CSV)",
                data=csv_str,
                file_name="analysis_summary.csv",
                mime="text/csv",
                key="download_csv",
            )

    else:
        # ä½¿ç”¨æ–¹æ³•ã®èª¬æ˜
        with st.expander("ğŸ“– ä½¿ç”¨æ–¹æ³•ãƒ»ç‰¹å¾´"):
            st.markdown("""
            ### ğŸ¯ ã“ã®æ©Ÿèƒ½ã«ã¤ã„ã¦
            è‡ªç„¶è¨€èªã§ã®æŒ‡ç¤ºã‚’å…¥åŠ›ã™ã‚‹ã ã‘ã§ã€AIãŒè‡ªå‹•çš„ã«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºãƒ»åˆ†æã—ã¾ã™ã€‚

            ### ğŸ“ ä½¿ç”¨æ–¹æ³•
            1. **APIã‚­ãƒ¼è¨­å®š**: OpenAI APIã‚­ãƒ¼ã¾ãŸã¯å¯¾å¿œãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ã‚­ãƒ¼ã‚’å…¥åŠ›
            2. **ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: åˆ†æã—ãŸã„CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            3. **ãƒ†ã‚­ã‚¹ãƒˆåˆ—é¸æŠ**: åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚«ãƒ©ãƒ ã‚’é¸æŠ
            4. **åˆ†ææŒ‡ç¤ºå…¥åŠ›**: è‡ªç„¶ãªè¨€è‘‰ã§åˆ†æã—ãŸã„å†…å®¹ã‚’å…¥åŠ›
            5. **åˆ†æå®Ÿè¡Œ**: AIãŒæŒ‡ç¤ºã‚’è§£é‡ˆã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ

            ### ğŸš€ ä¸»ãªæ©Ÿèƒ½
            - **è‡ªç„¶è¨€èªç†è§£**: ã€Œãƒã‚¸ãƒ†ã‚£ãƒ–ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†æã€ãªã©ã®æŠ½è±¡çš„ãªæŒ‡ç¤ºã«å¯¾å¿œ
            - **è‡ªå‹•ãƒ‡ãƒ¼ã‚¿æŠ½å‡º**: æŒ‡ç¤ºã«åŸºã¥ã„ã¦é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•æŠ½å‡º
            - **é«˜åº¦ãªåˆ†æ**: LLMã«ã‚ˆã‚‹è©³ç´°ãªåˆ†æã¨ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ
            - **ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ´»ç”¨**: ãƒˆãƒ”ãƒƒã‚¯ã‚„æ„Ÿæƒ…åˆ†æçµæœã‚’æ´»ç”¨ã—ãŸç²¾å¯†ãªæŠ½å‡º

            ### ğŸ’¡ æŒ‡ç¤ºã®ä¾‹
            - **è¦ç´„ç³»**: "ãƒã‚¸ãƒ†ã‚£ãƒ–ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’è¦ç´„"
            - **åˆ†æç³»**: "å•†å“ã®å“è³ªã«ã¤ã„ã¦è¨€åŠã—ã¦ã„ã‚‹å†…å®¹ã‚’åˆ†æ"
            - **æŠ½å‡ºç³»**: "æ”¹å–„ææ¡ˆã‚’å«ã‚€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç‰¹å®š"
            - **æ¯”è¼ƒç³»**: "æº€è¶³åº¦ã®é«˜ã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨ä½ã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æ¯”è¼ƒ"

            ### âš ï¸ æ³¨æ„äº‹é …
            - **APIåˆ¶é™**: å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†æ™‚ã¯APIåˆ¶é™ã«æ³¨æ„
            - **å‡¦ç†æ™‚é–“**: ãƒ‡ãƒ¼ã‚¿é‡ã«å¿œã˜ã¦å‡¦ç†æ™‚é–“ãŒå¢—åŠ ã—ã¾ã™
            - **ç²¾åº¦**: AIã®è§£é‡ˆã®ãŸã‚ã€è¤‡é›‘ãªæŒ‡ç¤ºã¯æ®µéšçš„ã«å®Ÿè¡Œã‚’æ¨å¥¨
            - **ã‚³ã‚¹ãƒˆ**: ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã«å¿œã˜ã¦APIåˆ©ç”¨æ–™é‡‘ãŒç™ºç”Ÿã—ã¾ã™

            ### ğŸ”§ å¯¾å¿œãƒ‡ãƒ¼ã‚¿å½¢å¼
            - **CSV**: UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¨å¥¨
            - **ãƒ†ã‚­ã‚¹ãƒˆã‚«ãƒ©ãƒ **: æ—¥æœ¬èªãƒ»è‹±èªå¯¾å¿œ
            - **ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿**: ãƒˆãƒ”ãƒƒã‚¯ã€æ„Ÿæƒ…ã€åˆ†é¡ã‚«ãƒ©ãƒ ã‚’è‡ªå‹•æ¤œå‡º
            """)


if __name__ == "__main__":
    main()